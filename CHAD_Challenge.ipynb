{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29060aca-74d0-4368-9ad5-512db67fa2a4",
   "metadata": {},
   "source": [
    "# CHAD Challenge\n",
    "\n",
    "For this challenge you will try to predict who survives on the Titanic. We give you a template notebook that modifies the features, performs cross validation, and generates the result csv for Kaggle.\n",
    "\n",
    "**IMPORTANT NOTE** Kaggle limits to 5 submissions per day so please use them wisely.\n",
    "\n",
    "Running the code below should produce a `results.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ca7485-0209-4d1d-b877-a3452337b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a507170-4799-4ce6-89ad-d963edd2c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(\"titanic\", \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(\"titanic\", \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55924d82-b92d-4fd3-8b86-d74fa37a8ced",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "A very important part of machine learning is feature engineering. This requires analyzing and modyfing the features (or columns) of the dataset to both work with the model and also help the model better learn the features to generate a prediction.\n",
    "\n",
    "Below is some fairly basic feature engineering that does the following:\n",
    "* Remove all non-relevant columns that are not needed for the model to learn\n",
    "* Encoding categorical features\n",
    "* Fix values that are NaN by removing the observation\n",
    "* Seperates the features from the labels\n",
    "* Normalizing the numerical features\n",
    "\n",
    "### Keeping Only Relevant Columns\n",
    "\n",
    "\"Put the women and children in and lower away\" -- Captain Jack Smith (Titanic 1999)\n",
    "\n",
    "Knowing some background on the Titanic (or just watching the movie), it can be inferred that certain features like sex, age, pclass, and fare are a good indicators on if a person surived on the Titanic. Features like the person's name do not give insight, or the model insight, for if the person surived or not. The following features will be used by the model to predict if the person survived:\n",
    "* Pclass\n",
    "* Sex\n",
    "* Age\n",
    "* Fare\n",
    "\n",
    "Do you think any other features should be kept in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7f9b39-eef6-4e77-b4bb-c9f3ec609c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df, features=[\"PassengerId\", \"Name\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\", \"Embarked\"]):\n",
    "    return df.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05070ee2-6a82-4232-a0dd-f3d43d247696",
   "metadata": {},
   "source": [
    "## Fixing categorical Values\n",
    "\n",
    "A categorical feature is a feature that has classes instead of numerical values. For example Sex, and Embarked are all categorical features because they are not floats and have distinct values that represent each possible class (for example male or female). Pclass could be considered a categorical feature two because it is not continuous. Name is also categorical because, but it is a one class per one observation, so it is not helpful.\n",
    "\n",
    "Two ways to encode the categorical value is to:\n",
    "* [Ordinally Encode](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) the feature, by assigning a value to each class in the feature with the lower the value being the more frequent the class.\n",
    "\n",
    "For example to Ordinally Encode `X = [[\"apple\"], [\"orange\"], [\"orange\"], [\"pear\"]]` it will result in `[[1], [0], [0], [2]]`\n",
    "\n",
    "* [One Hot Encode](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) the feature, which spreads out the feature into several features which are 1 for if the class is present and 0 otherwise.\n",
    "\n",
    "For example to One Hot Encode `X = [[\"apple\"], [\"orange\"], [\"orange\"], [\"pear\"]]` it will result in `[[1,0,0], [0,1,0], [0,1,0], [0,0,1]]`\n",
    "\n",
    "Below I provide functions to encode the dataframe both ways, but I will be use Ordinal encoding for my feature engineering. There are also other categorical encoders like Target Encoders and Label Encoders, but I would encourage with experimenting with these two encoders for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95f7d1d-e166-4d7a-98bf-dbfccac504a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, feature, encoders):\n",
    "    df = deepcopy(df)\n",
    "    if encoders.get(feature) is None:\n",
    "        enc = OrdinalEncoder()\n",
    "        enc.fit(df[[feature]].values)\n",
    "        encoders[feature] = enc\n",
    "    else:\n",
    "        enc = encoders.get(feature)\n",
    "    df[feature] = enc.transform(df[[feature]].values)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode(df, feature, encoders):\n",
    "    df = deepcopy(df)\n",
    "    if encoders.get(feature) is None:\n",
    "        enc = OneHotEncoder()\n",
    "        encoders[feature] = enc\n",
    "        enc.fit(df[[feature]].values)\n",
    "    else:\n",
    "        enc = encoders.get(feature)\n",
    "\n",
    "    one_hot_enc = enc.transform(df[[feature]]).toarray()\n",
    "    df = df.drop([feature], axis=1)\n",
    "    for i, new_feat in enumerate(enc.get_feature_names_out([feature])):\n",
    "        df[new_feat] = one_hot_enc[:,i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391d3c6-b4da-4e78-ac78-a555c0a301ee",
   "metadata": {},
   "source": [
    "## Handling NaN's\n",
    "\n",
    "A NaN or Not a Number is like a null in pandas. This can really muck up the machine learning model, so it is best to remove the the values. As seen below only three features have NaN:\n",
    "* Age\n",
    "* Cabin, but this is removed as a feature\n",
    "* Embarked, but this is also removed as a feature\n",
    "\n",
    "Removing observations with NaN is not ideal because we are removing valuable data because one value has a NaN. Instead we can \"fill in\" the NaN with a value using the following means:\n",
    "* If the feature is a categorical feature, fill in the NaN with the most common class (the mode) for that feature\n",
    "* If the feature is a numerical feature, fill in the NaN with the average value of the feature\n",
    "\n",
    "For the Age we will fill in the NaNs with the average age. However you can group by other features in the dataset get the average of that group. This is a smarter NaN fill, but it will be left as an exercise for the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0864b121-de1e-410f-af7e-123afdc21647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a5a7be-e2ff-456a-a322-14d714c2030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df, feature):\n",
    "    df = deepcopy(df)\n",
    "    if df[feature].dtype == object:\n",
    "        # get the mode for categorical values\n",
    "        mode = df[feature].mode()[0]\n",
    "        df[feature] = df[feature].fillna(mode)\n",
    "    elif df[feature].dtype == float:\n",
    "        # get the average for numerical values\n",
    "        avr = df[feature].mean().item()\n",
    "        df[feature] = df[feature].fillna(avr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd61b5-8d97-4387-a19e-70ef08ac995a",
   "metadata": {},
   "source": [
    "## Get Labels\n",
    "\n",
    "The training dataset should have features which we use as values in classifying if a person survived, and a label which is used by the model to correlate those features to that label. It is important that we split the two up before feeding them into training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665c8cdb-2868-4e90-bfb4-16ab4f22ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df, label):\n",
    "    y = df[label].values\n",
    "    X = df.drop([label], axis=1).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817ba66-a68c-4991-baf7-c3f0ea73ebdb",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "\n",
    "Finally we have all data as numbers and there are no NaNs. We want to scale the data. Having the data be within a manageable range for the model because it reduces outliers and ensures the data is all on the same scale. But make sure the avoid the label. For this we are using a MinMaxScaler which as the formula as follows:\n",
    "\n",
    "$$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d6f709-bdfd-4698-8f8b-39271b28a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X, encoders):\n",
    "    if encoders.get(\"scaler\") is None:\n",
    "        enc = MinMaxScaler()\n",
    "        encoders[\"scaler\"] = enc\n",
    "        enc.fit(X)\n",
    "    else:\n",
    "        enc = encoders.get(\"scaler\")\n",
    "\n",
    "    return enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac23108-04a1-4049-9b60-3226321962d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df, label=None, encoders={}):\n",
    "    # remove the features\n",
    "    rem_feature_list = [\"PassengerId\", \"Name\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "    df = remove_features(df, rem_feature_list)\n",
    "\n",
    "    # encode the categorical data 'Sex'\n",
    "    # TODO: replace with a better encoder or leave as is\n",
    "    df = ordinal_encode(df, 'Sex', encoders)\n",
    "\n",
    "    # fill NaN values\n",
    "    df = fill_na(df, 'Age')\n",
    "    df = fill_na(df, 'Fare')\n",
    "\n",
    "    if label is not None:\n",
    "        # get label\n",
    "        X, y = get_label(df, label)\n",
    "    else:\n",
    "        X = df.values\n",
    "        y = None\n",
    "\n",
    "    # scale the data\n",
    "    X = scale_data(X, encoders)\n",
    "    \n",
    "    return X, y, encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598744d8-d24d-41f7-9a5d-1fdf20b2947b",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "With the features in a more suitable state, lets train our model. In this learning session you learned about three different model types for classification:\n",
    "* [Support Vector Classifiers (SVC)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* [Random Forest Classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [K Nearest Neighbor Classifiers (KNN)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "Below I use SVC but I encourage you to try the different models above. Also try out different model parameters in order to get the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768390e4-99d3-4496-9c28-f6e74d5ea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    clf = SVC()\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efaade7-4133-4b3c-94fb-2ca5c29efc75",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "In Machine Learning, you would initially be given a dataset, and you would split up the dataset into training and test datasets. Kaggle does that for us by giving us the labeled training dataset `train.csv` and the unlabelled test datset `test.csv`. However we want to see how the model would perform on data it has never seen before. This involves splitting up the training dataset into the train dataset and the validation dataset. We use the train dataset to train the model, the validation dataset to check if the model is ready for the test dataset. The test datasets accuracy will be what your CHAD award will be judged on.\n",
    "\n",
    "There are two ways to split up a model. One is to do a train/test split which splits the data by a ratio which is usually 80% train dataset and 20% test/validation dataset. However a better method is to do K fold cross validation. Which splits the dataset similar to the train/test split, but does it K number of times. This way the model can be trained on all the and be validated with the K fold of the validation dataset. Both methods are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5910e8-23e0-4f45-a1a4-25e3824ac670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_test_split(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Model Accuracy: {acc:.4f}\")\n",
    "\n",
    "def run_cross_validation(X, y):\n",
    "    accuracies = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_val, y_val = X[val_index], y[val_index]\n",
    "\n",
    "        model = train_model(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        print(f\"K Fold {i} Accuracy: \\t{acc:.4f}\")\n",
    "        accuracies.append(acc)\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Average Accuracy: \\t{sum(accuracies)/len(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e82bf3-dfc7-413c-b181-7c511fe03087",
   "metadata": {},
   "source": [
    "## Putting it All Together\n",
    "\n",
    "Lets train the model with modified features and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c89c97-1a0e-4888-a9d3-722b310dafa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold 0 Accuracy: \t0.7877\n",
      "K Fold 1 Accuracy: \t0.7640\n",
      "K Fold 2 Accuracy: \t0.7753\n",
      "K Fold 3 Accuracy: \t0.7360\n",
      "K Fold 4 Accuracy: \t0.8034\n",
      "------------------------------\n",
      "Average Accuracy: \t0.7733\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    X_train, y_train, encoders = engineer_features(train_df, 'Survived')\n",
    "    run_cross_validation(X_train, y_train)\n",
    "    model = train_model(X_train, y_train)\n",
    "    return model, encoders\n",
    "clf_model, clf_encoders = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58d84ac7-5940-43bb-bbb0-53235ab2eb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_report(model, encoders):\n",
    "    report_df = test_df[['PassengerId']]\n",
    "    \n",
    "    X_test, _, _ = engineer_features(test_df, encoders=encoders)\n",
    "    y_preds = model.predict(X_test)\n",
    "    report_df['Survived'] = y_preds\n",
    "\n",
    "    report_df.to_csv(\"report.csv\", index=False)\n",
    "    \n",
    "    return report_df\n",
    "\n",
    "generate_report(clf_model, clf_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983ecd1-e148-4ab7-821a-2034f9b44c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
